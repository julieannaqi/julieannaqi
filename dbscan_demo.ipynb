{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJqX9saV2HIUWu+PUFMKdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julieannaqi/julieannaqi/blob/main/dbscan_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrVNFUi1oG4g",
        "outputId": "86b9a6c4-5208-486a-a94e-92ce5974c689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmwqsw7M_kd-",
        "outputId": "652f9d40-39a1-4fba-d07f-540bb7f5be9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'juile.csv' with the actual filename if it's different\n",
        "df = pd.read_csv('/content/sampledata.csv')\n",
        "\n",
        "# Display the contents of the CSV file\n",
        "print(df)\n",
        "df_slice = df.iloc[:1000, :10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUP_Vsahn0TQ",
        "outputId": "3dd99f8d-abd3-4293-d093-10a489e30cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          ioc_match_id     event_time       src_host  \\\n",
            "0      1773_362000776412_0_60382090314  1701618689736  10.15.149.168   \n",
            "1      1773_361424542980_0_59299513186  1701589169373  10.15.149.168   \n",
            "2      1773_361424542980_0_59327455359  1701589169373  10.15.149.168   \n",
            "3      1773_361424542980_0_59327639236  1701589169373  10.15.149.168   \n",
            "4      1773_362000776412_0_60440942415  1701618689736  10.15.149.168   \n",
            "...                                ...            ...            ...   \n",
            "99995  1773_361569283028_0_60382090483  1701596405801  10.20.100.250   \n",
            "99996  1773_361569283028_0_60724428162  1701596405801  10.20.100.250   \n",
            "99997  1773_361569283121_0_60362960162  1701596405801   10.20.106.39   \n",
            "99998  1773_361569283121_0_60374602795  1701596405801   10.20.106.39   \n",
            "99999  1773_361569283121_0_60650052021  1701596405801   10.20.106.39   \n",
            "\n",
            "            indicator  confidence severity indicator_type  originator  \\\n",
            "0        77.90.185.71          87      low             ip           0   \n",
            "1      198.235.24.186          99   medium             ip           0   \n",
            "2      198.235.24.186         100      low             ip           0   \n",
            "3      198.235.24.186         100      low             ip           0   \n",
            "4        77.90.185.71          87   medium             ip           0   \n",
            "...               ...         ...      ...            ...         ...   \n",
            "99995   77.90.185.240          87      low             ip           0   \n",
            "99996   77.90.185.240          87   medium             ip           0   \n",
            "99997   45.129.14.236          95      low             ip           0   \n",
            "99998   45.129.14.236          95      low             ip           0   \n",
            "99999   45.129.14.236          94   medium             ip           0   \n",
            "\n",
            "       source_feed_id event.action  ... event.src_ip count event.src_port  \\\n",
            "0                 260       ACCEPT  ...          NaN     1          47250   \n",
            "1                 469       ACCEPT  ...          NaN     1          56140   \n",
            "2                 280       ACCEPT  ...          NaN     1          56140   \n",
            "3                 156       ACCEPT  ...          NaN     1          56140   \n",
            "4                 469       ACCEPT  ...          NaN     1          47250   \n",
            "...               ...          ...  ...          ...   ...            ...   \n",
            "99995             260       ACCEPT  ...          NaN     1          52780   \n",
            "99996             469       ACCEPT  ...          NaN     1          52780   \n",
            "99997             260       ACCEPT  ...          NaN     1          44925   \n",
            "99998              18       ACCEPT  ...          NaN     1          44925   \n",
            "99999             469       ACCEPT  ...          NaN     1          44925   \n",
            "\n",
            "      event.dest_port      timestamp     event.sourcetype  \\\n",
            "0                8080  1701618689736  ULink: AWS VPC Flow   \n",
            "1               32400  1701589169373  ULink: AWS VPC Flow   \n",
            "2               32400  1701589169373  ULink: AWS VPC Flow   \n",
            "3               32400  1701589169373  ULink: AWS VPC Flow   \n",
            "4                8080  1701618689736  ULink: AWS VPC Flow   \n",
            "...               ...            ...                  ...   \n",
            "99995           10000  1701596405801  ULink: AWS VPC Flow   \n",
            "99996           10000  1701596405801  ULink: AWS VPC Flow   \n",
            "99997           56107  1701596405801  ULink: AWS VPC Flow   \n",
            "99998           56107  1701596405801  ULink: AWS VPC Flow   \n",
            "99999           56107  1701596405801  ULink: AWS VPC Flow   \n",
            "\n",
            "                            source     itype hour minute  \n",
            "0      Spamhaus Extended Drop List   spam_ip   15   50-0  \n",
            "1             DShield Scanning IPs   scan_ip    7   30-0  \n",
            "2                   VoIP Blacklist    bot_ip    7   30-0  \n",
            "3       VoIP Blacklist by ScopServ  brute_ip    7   30-0  \n",
            "4             DShield Scanning IPs   scan_ip   15   50-0  \n",
            "...                            ...       ...  ...    ...  \n",
            "99995  Spamhaus Extended Drop List   spam_ip    9   40-0  \n",
            "99996         DShield Scanning IPs   scan_ip    9   40-0  \n",
            "99997  Spamhaus Extended Drop List   spam_ip    9   40-0  \n",
            "99998                      CI Army    bot_ip    9   40-0  \n",
            "99999         DShield Scanning IPs   scan_ip    9   40-0  \n",
            "\n",
            "[100000 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape, df_slice.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXbUP6jiFDGb",
        "outputId": "faf52d36-4eaa-4405-9040-926c61baf958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 23) (1000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
        "import h5py\n",
        "import pyarrow as pa\n",
        "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.utils.metaestimators import if_delegate_has_method"
      ],
      "metadata": {
        "id": "0LkR2DgDzdUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnABN5NanGIM"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(data, predicted_labels):\n",
        "        # homogeneity = homogeneity_score(true_labels, predicted_labels)\n",
        "        # completeness = completeness_score(true_labels, predicted_labels)\n",
        "        # v_measure = v_measure_score(true_labels, predicted_labels)\n",
        "        # adj_rand_index = adjusted_rand_score(true_labels, predicted_labels)\n",
        "        # adj_mutual_info = adjusted_mutual_info_score(true_labels, predicted_labels)\n",
        "        # we don't know the true label at the moment, so we can only return the sillhouette score.\n",
        "        silhouette_coeff = silhouette_score(data, predicted_labels)\n",
        "\n",
        "        # return {\n",
        "        #     \"Homogeneity\": homogeneity,\n",
        "        #     \"Completeness\": completeness,\n",
        "        #     \"V-Measure\": v_measure,\n",
        "        #     \"Adjusted Rand Index\": adj_rand_index,\n",
        "        #     \"Adjusted Mutual Information\": adj_mutual_info,\n",
        "        #     \"Silhouette Coefficient\": silhouette_coeff\n",
        "        # }\n",
        "        return silhouette_coeff\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_slice"
      ],
      "metadata": {
        "id": "6SuAJWaPb1aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_numeric_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
        "\n",
        "# Numeric columns for imputation and scaling\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# ColumnTransformer to handle different transformations for different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(), non_numeric_cols),\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value=-1), numeric_cols),  # Apply imputer to numeric columns\n",
        "        ('scaler', StandardScaler(), numeric_cols)  # Apply scaler to numeric columns\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor)\n",
        "])\n",
        "\n",
        "# Fit and transform your data using the pipeline\n",
        "processed_data = pipeline.fit_transform(df)"
      ],
      "metadata": {
        "id": "xdzYkW2u3h8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Assuming 'df' is your Pandas DataFrame containing sparse data\n",
        "\n",
        "# Convert the DataFrame to a sparse matrix\n",
        "sparse_matrix = csr_matrix(processed_data)"
      ],
      "metadata": {
        "id": "A5W14Xlx-f21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%load_ext memory_profiler\n",
        "%memit\n",
        "from sklearn.cluster import DBSCAN\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already defined and fitted your pipeline to obtain processed_data\n",
        "\n",
        "# Create DBSCAN object with your desired parameters\n",
        "dbscan = DBSCAN(eps=0.1, min_samples=10)  # You might need to adjust the epsilon (eps) and min_samples\n",
        "\n",
        "# Fit DBSCAN to your processed data\n",
        "labels = dbscan.fit_predict(sparse_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYvAX7yx7yCq",
        "outputId": "640bc465-cb3e-4b46-e1a3-f5e7a30b920e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 261.85 MiB, increment: 0.88 MiB\n",
            "CPU times: user 525 ms, sys: 91.7 ms, total: 617 ms\n",
            "Wall time: 502 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'the silhouette score for dbscan alone was {calculate_metrics(processed_data, labels)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmEqGyaUDfvV",
        "outputId": "67890d37-822d-4a1d-81d2-39667c6889ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the silhouette score for dbscan alone was 0.9999627374626776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import cKDTree"
      ],
      "metadata": {
        "id": "mdfIoer3WQcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Cython\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuldtiQweEuX",
        "outputId": "945d6bc3-14c3-4270-f72c-e56c9dda08af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "def dbscan_kdtree_optimized(data, eps, min_pts):\n",
        "    n = data.shape[0]\n",
        "    visited = np.zeros(n, dtype=bool)\n",
        "    labels = np.zeros(n, dtype=int)\n",
        "    cluster_id = 0\n",
        "    tree = cKDTree(data, compact_nodes=True)\n",
        "\n",
        "    def expand_cluster(point_idx, neighbors, cluster_id):\n",
        "        labels[point_idx] = cluster_id\n",
        "        for point in neighbors:\n",
        "            if not visited[point]:\n",
        "                visited[point] = True\n",
        "                new_neighbors = tree.query_ball_point(data[point], eps)\n",
        "                if len(new_neighbors) >= min_pts:\n",
        "                    neighbors.extend([n for n in new_neighbors if n not in neighbors])\n",
        "            if labels[point] == -1:\n",
        "                labels[point] = cluster_id\n",
        "            elif labels[point] == 0:\n",
        "                labels[point] = cluster_id\n",
        "                new_point_neighbors = tree.query_ball_point(data[point], eps)\n",
        "                if len(new_point_neighbors) >= min_pts:\n",
        "                    neighbors.extend([n for n in new_point_neighbors if n not in neighbors])\n",
        "\n",
        "    for i in range(n):\n",
        "        if visited[i]:\n",
        "            continue\n",
        "        visited[i] = True\n",
        "        neighbors = tree.query_ball_point(data[i], eps)\n",
        "        if len(neighbors) < min_pts:\n",
        "            labels[i] = -1\n",
        "        else:\n",
        "            cluster_id += 1\n",
        "            expand_cluster(i, neighbors, cluster_id)\n",
        "\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "Apg8ZE-JW1cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to optimize DBSCAN using kd trees, so we don't have to compute the euclidean distance between each point pair combination."
      ],
      "metadata": {
        "id": "pBw0CCtDWQzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = processed_data.toarray()"
      ],
      "metadata": {
        "id": "eTJKpxQsZeK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%memit\n",
        "cluster_labels = dbscan_kdtree(data, eps=0.6, min_pts=10)\n",
        "print(f'the silhouette score for dbscan using kdtree optimization was {calculate_metrics(data, cluster_labels)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SRlh9MtYSta",
        "outputId": "36741be2-df97-4783-e2ac-8e0ab67083f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 283.47 MiB, increment: 0.00 MiB\n",
            "the silhouette score for dbscan using kdtree optimization was -0.19665295913277306\n",
            "CPU times: user 982 ms, sys: 61 ms, total: 1.04 s\n",
            "Wall time: 1.34 s\n"
          ]
        }
      ]
    }
  ]
}